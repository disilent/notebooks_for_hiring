{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbd7f0b6-fd5c-4670-915d-28a5cd4f8724",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Парсинг новостей\n",
    "\n",
    "Скорее всего, новости, оказавшие наибольшее влияние на потребительский спрос, находятся на наиболее популярных новостных ресурсах.\n",
    "\n",
    "Рейтинг новостных ресурсов по посещаемости - лето 2020 г.\n",
    "<https://infoselection.ru/infokatalog/novosti-smi/smi/item/249-20-samykh-poseshchaemykh-novostnykh-resursov-runeta>\n",
    "\n",
    "Для парсинга я проверил топ 5 по посещаемости:\n",
    "1. Комсомольская правда - парсинг возможен, через запрос к их cdn можно получать страницы новостей по датам, но сайт сильно разделен по категориям, что вызывает сложности, пока не делал, если нужно будет, сделаю.\n",
    "2. РИА Новости - всё ок.\n",
    "3. Lenta.ru - всё ок.\n",
    "4. РосБизнесКонсалтинг - архив онлайн газеты не доступен для 2020 года.\n",
    "5. Московский Комсомолец (МК) - имеет архив по датам, но при обращении выдает ошибку 404.\n",
    "\n",
    "Поэтому парсинг я осуществляю для двух популярных новостных площадок - РИА Новости (52581 новость) и Lenta.ru (19940 новостей)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1cea554a-deb9-4b6e-aa7e-8c2b99fb8639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import dateparser\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Callable\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "start_date = datetime.date(2020, 2, 1)\n",
    "end_date   = datetime.date(2020, 5, 1) #не включительно\n",
    "\n",
    "session = requests.Session()\n",
    "session.headers.update({'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) '\n",
    "                                      'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                                      'Chrome/104.0.5112.102 Safari/537.36'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3548636-066c-460b-a9ea-820051ca9563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_list_by_date_ria(date: datetime.date):\n",
    "    date = date.strftime('%Y%m%d')\n",
    "    \n",
    "    page = 1\n",
    "    news_list = []\n",
    "        \n",
    "    while True:\n",
    "        r = session.get(f'https://ria.ru/{date}/', params={'page': page})\n",
    "        \n",
    "        if r.status_code == 404:\n",
    "            break\n",
    "        if not r.ok:\n",
    "            continue\n",
    "            \n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        for item in soup.find(\"div\", class_=\"list\").children:\n",
    "            if item.name != 'div':\n",
    "                continue\n",
    "            \n",
    "            data = {}\n",
    "            get_text = lambda res: res.text if res else None\n",
    "            data['name']  = get_text(item.find(class_='list-item__content'))\n",
    "            data['date']  = get_text(item.find(class_='list-item__date'))\n",
    "            data['date']  = str(dateparser.parse(data['date'])) if data['date'] else None\n",
    "            data['views'] = get_text(item.find(class_='list-item__views-text'))\n",
    "            data['tags']  = list(map(get_text, item.find_all(class_='list-tag__text')))\n",
    "            data['link']  = item.find('a')['href']\n",
    "        \n",
    "            news_list.append(data)\n",
    "        page += 1\n",
    "        \n",
    "    return news_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190856db-ffe0-4724-bb98-8319abcee10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_list_by_date_lenta(date: datetime.date):\n",
    "    date = date.strftime('%Y/%m/%d')\n",
    "    \n",
    "    page = 1\n",
    "    news_list = []\n",
    "        \n",
    "    while True:\n",
    "        r = session.get(f'https://lenta.ru/{date}/page/{page}/')\n",
    "        \n",
    "        if not r.ok:\n",
    "            continue\n",
    "            \n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        items = soup.find_all(\"li\", class_=\"archive-page__item _news\")\n",
    "        \n",
    "        if not items:\n",
    "            break\n",
    "        \n",
    "        for item in items:\n",
    "            data = {}\n",
    "            get_text = lambda res: res.text if res else None\n",
    "            data['name']  = get_text(item.find('h3'))\n",
    "            data['date']  = get_text(item.find('time'))\n",
    "            data['date']  = str(dateparser.parse(data['date'])) if data['date'] else None\n",
    "            data['link']  = item.find('a')['href']\n",
    "            data['link']  = ('https://lenta.ru' if data['link'][0] == '/' else '') + data['link']\n",
    "        \n",
    "            news_list.append(data)\n",
    "            \n",
    "        page += 1\n",
    "        \n",
    "    return news_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90dc422e-e33f-4e23-934b-d497978c904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_list(get_by_date: Callable, \n",
    "                  start_date: datetime.date, \n",
    "                  end_date: datetime.date,\n",
    "                  delta=datetime.timedelta(days=1)):\n",
    "    date = start_date\n",
    "    news_list = []\n",
    "    \n",
    "    for _ in tqdm(range((end_date - start_date).days), desc=\"Days: \"):\n",
    "        news_list += get_by_date(date)\n",
    "        date += delta\n",
    "        \n",
    "    return news_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70a6cbe-d3b8-4778-947c-5c03a43a2dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_news_list(name: str,\n",
    "                    path: str,\n",
    "                    get_by_date: Callable,\n",
    "                    start_date: datetime.date = start_date, \n",
    "                    end_date: datetime.date = end_date):\n",
    "    print(f'Getting {name} news by days:')\n",
    "    data = get_news_list(get_by_date, start_date, end_date)\n",
    "    print('Writing into csv')\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(path)\n",
    "    print(f'Done: {len(df)} news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1003461a-35e8-41cf-8171-a8be59dbc822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting RIA news by days:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ef2ca14be3414f9682a697268d0b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Days:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing into csv\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "parse_news_list(name='RIA',\n",
    "                path='parsed_ria_news_list.csv',\n",
    "                get_by_date=get_news_list_by_date_ria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fa0be2-ab71-47f8-81e8-a399f2e131cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_news_list(name='Lenta.ru',\n",
    "                path='parsed_lenta_news_list.csv',\n",
    "                get_by_date=get_news_list_by_date_lenta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "506bc55d-3855-4524-9f21-c47c6fb7609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ria_text(soup: BeautifulSoup):\n",
    "    article = soup.find('div', class_='article__body')\n",
    "    if not article:\n",
    "        return ''\n",
    "    \n",
    "    text = ''\n",
    "    for item in article.children:\n",
    "        if item.name == 'div' and 'data-type' in item.attrs and item['data-type'] == 'text':\n",
    "            text += item.text + '\\n'\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a34c8d20-6067-4f88-927c-ac9e12bea580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lenta_text(soup: BeautifulSoup):\n",
    "    items = soup.find_all('p', class_='topic-body__content-text')\n",
    "    text = ''\n",
    "    \n",
    "    for item in items:\n",
    "        text += item.text + '\\n'\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cdf9430d-d5cc-4724-9ed9-5fff35105163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(link: str, extract_text: Callable, attempt: int=0, max_attempt: int=5):\n",
    "    if attempt >= max_attempt:\n",
    "        return ''\n",
    "    \n",
    "    r = session.get(link)\n",
    "    if not r.ok:\n",
    "        sleep(1)\n",
    "        return get_text(link, extract_text, attempt + 1, max_attempt)\n",
    "\n",
    "    text = extract_text(BeautifulSoup(r.text, 'html.parser'))\n",
    "    if not text:\n",
    "        return get_text(link, extract_text, attempt + 1, max_attempt)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7b8840f6-b9b1-4c77-9175-951002a3693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_texts(name: str, \n",
    "                path: str, \n",
    "                folder: str,\n",
    "                extract_text: Callable,\n",
    "                max_attempt=5):\n",
    "    print(f'Getting {name} news texts:')\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    \n",
    "    folder = Path(folder)\n",
    "    if not folder.exists():\n",
    "        folder.mkdir()\n",
    "    \n",
    "    for row in tqdm(df.itertuples(), total=len(df), desc='News: '):\n",
    "        filename = folder / (str(row.Index) + '.txt')\n",
    "        if filename.exists():\n",
    "            continue\n",
    "        \n",
    "        text = get_text(row.link, extract_text)\n",
    "        if text:  \n",
    "            with open(filename, 'w', encoding='utf-8') as file:\n",
    "                file.write(text)\n",
    "    print(f'Done {len(df)} news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "08f8a32d-1f58-4db4-ab57-5a1b511f4ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting RIA news texts:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ea5c07afba4476a71a530e62c205ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "News:   0%|          | 0/52581 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 52581 news\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "        parse_texts(name='RIA', \n",
    "            path='parsed_ria_news_list.csv', \n",
    "            folder='parsed_ria_texts',\n",
    "            extract_text=extract_ria_text)\n",
    "    except Exception:\n",
    "        continue\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16b2af2-77bb-4241-a07f-b6d19ae1b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_texts(name='Lenta.ru', \n",
    "            path='parsed_lenta_news_list.csv', \n",
    "            folder='parsed_lenta_texts',\n",
    "            extract_text=extract_lenta_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449f1bc3-6f8b-4957-9b25-72841bd58843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unite_datasets(path_folder: dict, path: str, columns: list):\n",
    "    df = None\n",
    "    for csv_path in path_folder:\n",
    "        df_cur = pd.read_csv(csv_path, index_col=0)[columns]\n",
    "        texts = [''] * len(df_cur)\n",
    "        \n",
    "        \n",
    "        for file in Path(path_folder[csv_path]).iterdir():\n",
    "            name = file.name\n",
    "            if not name.endswith('.txt'):\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                ind = int(name[:-4])\n",
    "            except Exception:\n",
    "                continue\n",
    "            \n",
    "            with open(file, encoding='utf-8') as f:\n",
    "                texts[ind] = f.read()\n",
    "                \n",
    "        df_cur['text'] = pd.Series(texts, index=df_cur.index)\n",
    "        \n",
    "        if df is None:\n",
    "            df = df_cur\n",
    "        else:\n",
    "            df = pd.concat([df, df_cur], ignore_index=True)\n",
    "            \n",
    "    if df is not None:\n",
    "        df.to_csv(path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a6d496a9-a100-45c8-a925-25cf4e986604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Театральные премьеры февраля: \"Садко\", \"Чайка\"...</td>\n",
       "      <td>2020-02-01 23:46:00</td>\n",
       "      <td>https://ria.ru/20200201/1564150494.html</td>\n",
       "      <td>МОСКВА, 1 фев – РИА Новости, Наталия Курова. В...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>В США прооперировали архиепископа Кипрского</td>\n",
       "      <td>2020-02-01 23:39:00</td>\n",
       "      <td>https://ria.ru/20200201/1564152142.html</td>\n",
       "      <td>АФИНЫ, 1 фев - РИА Новости. Архиепископ Кипрск...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>В Госдуме прокомментировали идею об упоминании...</td>\n",
       "      <td>2020-02-01 23:36:00</td>\n",
       "      <td>https://ria.ru/20200201/1564152109.html</td>\n",
       "      <td>МОСКВА, 1 фев - РИА Новости. Первый зампред ко...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>В Киеве рассчитывают, что местные выборы на Ук...</td>\n",
       "      <td>2020-02-01 23:27:00</td>\n",
       "      <td>https://ria.ru/20200201/1564152051.html</td>\n",
       "      <td>КИЕВ, 1 фев - РИА Новости. Помощник президента...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Клишас оценил предложение патриарха об упомина...</td>\n",
       "      <td>2020-02-01 23:26:00</td>\n",
       "      <td>https://ria.ru/20200201/1564152029.html</td>\n",
       "      <td>МОСКВА, 1 фев - РИА Новости. Предложение об уп...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name                 date  \\\n",
       "0  Театральные премьеры февраля: \"Садко\", \"Чайка\"...  2020-02-01 23:46:00   \n",
       "1       В США прооперировали архиепископа Кипрского   2020-02-01 23:39:00   \n",
       "2  В Госдуме прокомментировали идею об упоминании...  2020-02-01 23:36:00   \n",
       "3  В Киеве рассчитывают, что местные выборы на Ук...  2020-02-01 23:27:00   \n",
       "4  Клишас оценил предложение патриарха об упомина...  2020-02-01 23:26:00   \n",
       "\n",
       "                                      link  \\\n",
       "0  https://ria.ru/20200201/1564150494.html   \n",
       "1  https://ria.ru/20200201/1564152142.html   \n",
       "2  https://ria.ru/20200201/1564152109.html   \n",
       "3  https://ria.ru/20200201/1564152051.html   \n",
       "4  https://ria.ru/20200201/1564152029.html   \n",
       "\n",
       "                                                text  \n",
       "0  МОСКВА, 1 фев – РИА Новости, Наталия Курова. В...  \n",
       "1  АФИНЫ, 1 фев - РИА Новости. Архиепископ Кипрск...  \n",
       "2  МОСКВА, 1 фев - РИА Новости. Первый зампред ко...  \n",
       "3  КИЕВ, 1 фев - РИА Новости. Помощник президента...  \n",
       "4  МОСКВА, 1 фев - РИА Новости. Предложение об уп...  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = unite_datasets({\n",
    "    'parsed_ria_news_list.csv': 'parsed_ria_texts',\n",
    "    'parsed_lenta_news_list.csv': 'parsed_lenta_texts'\n",
    "}, 'parsed_raw_texts.csv', ['name', 'date', 'link'])\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
